{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IyNYn84mhbO9",
        "outputId": "f3e0e9c8-de65-4b8f-adc0-009747623a2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.10/dist-packages (0.1.23)\n",
            "Requirement already satisfied: langchainhub in /usr/local/lib/python3.10/dist-packages (0.1.21)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.2.16)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.12.3)\n",
            "Requirement already satisfied: langchain_chroma in /usr/local/lib/python3.10/dist-packages (0.1.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.0.32)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (3.10.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.38 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.2.38)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (0.1.110)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (1.26.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain_community) (8.5.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (1.43.0)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (24.1)\n",
            "Requirement already satisfied: types-requests<3.0.0.0,>=2.31.0.2 in /usr/local/lib/python3.10/dist-packages (from langchainhub) (2.32.0.20240712)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.8.2)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.112.2)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.6)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.6.3)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.12.2)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.19.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.27.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.5)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.4.4)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.2.0)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.12.5)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (30.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb) (3.10.7)\n",
            "Requirement already satisfied: httpx>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.27.2)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.2.4)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.22.0)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi>=0.95.2->chromadb) (0.38.4)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (3.8)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.38->langchain_community) (1.33)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.13.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.7.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: importlib-metadata<=8.4.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb) (8.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.65.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.27.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.27.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.48b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.48b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (71.0.4)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=1.9->chromadb) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain_community) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.23.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (13.8.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.20.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.24.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (13.0.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.27.0->chromadb) (1.2.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.15.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.20.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.38->langchain_community) (3.0.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.16.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain_community tiktoken langchain-openai langchainhub chromadb langchain beautifulsoup4 langchain_chroma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install grandalf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nLnt3fglpFU",
        "outputId": "d204deef-009c-4a21-c48b-5c9738d004c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: grandalf in /usr/local/lib/python3.10/dist-packages (0.8)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from grandalf) (3.1.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
        "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
        "os.environ['LANGCHAIN_API_KEY'] = \"your_langchain_key\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"]=\"multi_query_rag\""
      ],
      "metadata": {
        "id": "ENFfXWJ_iFwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "os.environ['OPENAI_API_KEY'] = getpass.getpass(\"OPENAI_API_KEY:\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuMia1rHiYbK",
        "outputId": "1a08501f-cc79-4497-bf83-3f2efdbaee32"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OPENAI_API_KEY:··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.runnable import RunnablePassthrough\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "\n",
        "llm = ChatOpenAI(model_name=\"gpt-4o-mini\")\n",
        "parser = StrOutputParser()\n",
        "emb = OpenAIEmbeddings()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zm0YCqgciq9H",
        "outputId": "ee076f19-185a-40d7-979b-333ff3a6aeb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt_template = \"\"\"You are an AI language model assistant. Your task is to generate three\n",
        "different versions of the given user question to retrieve relevant documents from a vector\n",
        "database. By generating multiple perspectives on the user question, your goal is to help\n",
        "the user overcome some of the limitations of the distance-based similarity search.\n",
        "Provide these alternative questions separated by newlines. Original question: {question}\"\"\"\n",
        "multi_prompt = ChatPromptTemplate.from_template(prompt_template)\n",
        "multi_prompt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6xdEp3VjKIB",
        "outputId": "17fe30fb-a52e-445d-d049-386213af5376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate three\\ndifferent versions of the given user question to retrieve relevant documents from a vector\\ndatabase. By generating multiple perspectives on the user question, your goal is to help\\nthe user overcome some of the limitations of the distance-based similarity search.\\nProvide these alternative questions separated by newlines. Original question: {question}'))])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mpromt_chain = multi_prompt | llm | parser\n",
        "mprompts = mpromt_chain.invoke({\"question\": \"What is the capital of France?\"})\n",
        "mprompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nGXCsTLKjXNp",
        "outputId": "a86e0fd7-aecb-457e-9dcf-ad40dd17b49a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"What city serves as the capital of France?  \\nCan you tell me the name of France's capital city?  \\nWhich city is recognized as the capital in France?  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [q.strip() for q in mprompts.split(\"\\n\") if q.strip()]\n",
        "queries"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2irrWrFqjlST",
        "outputId": "5b37f38b-6245-441a-b5e6-b66c9fe27caf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['What city serves as the capital of France?',\n",
              " \"Can you tell me the name of France's capital city?\",\n",
              " 'Which city is recognized as the capital in France?']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_queries_to_list(mprompts):\n",
        "    return [q.strip() for q in mprompts.split(\"\\n\") if q.strip()]"
      ],
      "metadata": {
        "id": "hX6sdXl8rPvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mpromt_chain = mpromt_chain | convert_queries_to_list\n",
        "mpromt_chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_h1scqWricJ",
        "outputId": "b7885565-1cd4-4363-ccc6-c88cca1ac7b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate three\\ndifferent versions of the given user question to retrieve relevant documents from a vector\\ndatabase. By generating multiple perspectives on the user question, your goal is to help\\nthe user overcome some of the limitations of the distance-based similarity search.\\nProvide these alternative questions separated by newlines. Original question: {question}'))])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x798de8061ba0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x798de8063ca0>, root_client=<openai.OpenAI object at 0x798de8244c10>, root_async_client=<openai.AsyncOpenAI object at 0x798de8061c00>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "| StrOutputParser()\n",
              "| RunnableLambda(convert_queries_to_list)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mpromt_chain.get_graph().print_ascii()                    # chain to generate multiple prompts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ImwSj-vkR9N",
        "outputId": "9933465a-212b-4ec0-99d3-93b1bbc2a14b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          +-------------+          \n",
            "          | PromptInput |          \n",
            "          +-------------+          \n",
            "                 *                 \n",
            "                 *                 \n",
            "                 *                 \n",
            "      +--------------------+       \n",
            "      | ChatPromptTemplate |       \n",
            "      +--------------------+       \n",
            "                 *                 \n",
            "                 *                 \n",
            "                 *                 \n",
            "          +------------+           \n",
            "          | ChatOpenAI |           \n",
            "          +------------+           \n",
            "                 *                 \n",
            "                 *                 \n",
            "                 *                 \n",
            "        +-----------------+        \n",
            "        | StrOutputParser |        \n",
            "        +-----------------+        \n",
            "                 *                 \n",
            "                 *                 \n",
            "                 *                 \n",
            "    +-------------------------+    \n",
            "    | convert_queries_to_list |    \n",
            "    +-------------------------+    \n",
            "                 *                 \n",
            "                 *                 \n",
            "                 *                 \n",
            "+--------------------------------+ \n",
            "| convert_queries_to_list_output | \n",
            "+--------------------------------+ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "webpage = \"https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452\"\n",
        "loader = WebBaseLoader(webpage)\n",
        "data = loader.load()\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=10)\n",
        "all_splits = text_splitter.split_documents(data)\n",
        "for i in range(len(all_splits)):\n",
        "    print(\"Chunk \",i,\" : \",all_splits[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xo8csWczlcc0",
        "outputId": "47aced6c-c8a8-4c48-c439-317cac9f546c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chunk  0  :  page_content='Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data ScienceOpen in appSign upSign inWriteSign upSign inINTUITIVE TRANSFORMERS SERIES NLPTransformers Explained Visually (Part 1): Overview of FunctionalityA Gentle Guide to Transformers, how they are used' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  1  :  page_content='are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.Ketan Doshi·FollowPublished inTowards Data Science·10 min read·Dec 13, 2020--23ListenSharePhoto by Arseny Togulev on UnsplashWe’ve been hearing a lot about Transformers and with good' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  2  :  page_content='with good reason. They have taken the world of NLP by storm in the last few years. The Transformer is an architecture that uses Attention to significantly improve the performance of deep learning NLP translation models. It was first introduced in the paper Attention is all you need and was quickly' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  3  :  page_content='quickly established as the leading architecture for most text data applications.Since then, numerous projects including Google’s BERT and OpenAI’s GPT series have built on this foundation and published performance results that handily beat existing state-of-the-art benchmarks.Over a series of' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  4  :  page_content='series of articles, I’ll go over the basics of Transformers, its architecture, and how it works internally. We will cover the Transformer functionality in a top-down manner. In later articles, we will look under the covers to understand the operation of the system in detail. We will also do a deep' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  5  :  page_content='do a deep dive into the workings of the multi-head attention, which is the heart of the Transformer.Here’s a quick summary of the previous and following articles in the series. My goal throughout will be to understand not just how something works but why it works that way.Overview of functionality' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  6  :  page_content='— this article (How Transformers are used, and why they are better than RNNs. Components of the architecture, and behavior during Training and Inference)How it works (Internal operation end-to-end. How data flows and what computations are performed, including matrix representations)Multi-head' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  7  :  page_content='Attention (Inner workings of the Attention module throughout the Transformer)Why Attention Boosts Performance (Not just what Attention does but why it works so well. How does Attention capture the relationships between words in a sentence)And if you’re interested in NLP applications in general, I' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  8  :  page_content='I have some other articles you might like.Beam Search (Algorithm commonly used by Speech-to-Text and NLP applications to enhance predictions)Bleu Score (Bleu Score and Word Error Rate are two essential metrics for NLP models)What is a TransformerThe Transformer architecture excels at handling text' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  9  :  page_content='text data which is inherently sequential. They take a text sequence as input and produce another text sequence as output. eg. to translate an input English sentence to Spanish.(Image by Author)At its core, it contains a stack of Encoder layers and Decoder layers. To avoid confusion we will refer to' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  10  :  page_content='refer to the individual layer as an Encoder or a Decoder and will use Encoder stack or Decoder stack for a group of Encoder layers.The Encoder stack and the Decoder stack each have their corresponding Embedding layers for their respective inputs. Finally, there is an Output layer to generate the' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  11  :  page_content='the final output.(Image by Author)All the Encoders are identical to one another. Similarly, all the Decoders are identical.(Image by Author)The Encoder contains the all-important Self-attention layer that computes the relationship between different words in the sequence, as well as a Feed-forward' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  12  :  page_content='layer.The Decoder contains the Self-attention layer and the Feed-forward layer, as well as a second Encoder-Decoder attention layer.Each Encoder and Decoder has its own set of weights.The Encoder is a reusable module that is the defining component of all Transformer architectures. In addition to' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  13  :  page_content='to the above two layers, it also has Residual skip connections around both layers along with two LayerNorm layers.(Image by Author)There are many variations of the Transformer architecture. Some Transformer architectures have no Decoder at all and rely only on the Encoder.What does Attention Do?The' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  14  :  page_content='Do?The key to the Transformer’s ground-breaking performance is its use of Attention.While processing a word, Attention enables the model to focus on other words in the input that are closely related to that word.eg. ‘Ball’ is closely related to ‘blue’ and ‘holding’. On the other hand, ‘blue’ is not' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  15  :  page_content='is not related to ‘boy’.The Transformer architecture uses self-attention by relating every word in the input sequence to every other word.eg. Consider two sentences:The cat drank the milk because it was hungry.The cat drank the milk because it was sweet.In the first sentence, the word ‘it’ refers' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  16  :  page_content='refers to ‘cat’, while in the second it refers to ‘milk. When the model processes the word ‘it’, self-attention gives the model more information about its meaning so that it can associate ‘it’ with the correct word.Dark colors represent higher attention (Image by Author)To enable it to handle more' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  17  :  page_content='more nuances about the intent and semantics of the sentence, Transformers include multiple attention scores for each word.eg. While processing the word ‘it’, the first score highlights ‘cat’, while the second score highlights ‘hungry’. So when it decodes the word ‘it’, by translating it into a' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  18  :  page_content='it into a different language, for instance, it will incorporate some aspect of both ‘cat’ and ‘hungry’ into the translated word.(Image by Author)Training the TransformerThe Transformer works slightly differently during Training and while doing Inference.Let’s first look at the flow of data during' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  19  :  page_content='during Training. Training data consists of two parts:The source or input sequence (eg. “You are welcome” in English, for a translation problem)The destination or target sequence (eg. “De nada” in Spanish)The Transformer’s goal is to learn how to output the target sequence, by using both the input' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  20  :  page_content='the input and target sequence.(Image by Author)The Transformer processes the data like this:The input sequence is converted into Embeddings (with Position Encoding) and fed to the Encoder.The stack of Encoders processes this and produces an encoded representation of the input sequence.The target' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  21  :  page_content='target sequence is prepended with a start-of-sentence token, converted into Embeddings (with Position Encoding), and fed to the Decoder.The stack of Decoders processes this along with the Encoder stack’s encoded representation to produce an encoded representation of the target sequence.The Output' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  22  :  page_content='Output layer converts it into word probabilities and the final output sequence.The Transformer’s Loss function compares this output sequence with the target sequence from the training data. This loss is used to generate gradients to train the Transformer during back-propagation.InferenceDuring' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  23  :  page_content='Inference, we have only the input sequence and don’t have the target sequence to pass as input to the Decoder. The goal of the Transformer is to produce the target sequence from the input sequence alone.So, like in a Seq2Seq model, we generate the output in a loop and feed the output sequence from' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  24  :  page_content='from the previous timestep to the Decoder in the next timestep until we come across an end-of-sentence token.The difference from the Seq2Seq model is that, at each timestep, we re-feed the entire output sequence generated thus far, rather than just the last word.Inference flow, after first timestep' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  25  :  page_content='timestep (Image by Author)The flow of data during Inference is:The input sequence is converted into Embeddings (with Position Encoding) and fed to the Encoder.The stack of Encoders processes this and produces an encoded representation of the input sequence.Instead of the target sequence, we use an' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  26  :  page_content='we use an empty sequence with only a start-of-sentence token. This is converted into Embeddings (with Position Encoding) and fed to the Decoder.The stack of Decoders processes this along with the Encoder stack’s encoded representation to produce an encoded representation of the target sequence.The' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  27  :  page_content='Output layer converts it into word probabilities and produces an output sequence.We take the last word of the output sequence as the predicted word. That word is now filled into the second position of our Decoder input sequence, which now contains a start-of-sentence token and the first word.Go' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  28  :  page_content='word.Go back to step #3. As before, feed the new Decoder sequence into the model. Then take the second word of the output and append it to the Decoder sequence. Repeat this until it predicts an end-of-sentence token. Note that since the Encoder sequence does not change for each iteration, we do not' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  29  :  page_content='we do not have to repeat steps #1 and #2 each time (Thanks to Michal Kučírka for pointing this out).Teacher ForcingThe approach of feeding the target sequence to the Decoder during training is known as Teacher Forcing. Why do we do this and what does that term mean?During training, we could have' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  30  :  page_content='have used the same approach that is used during inference. In other words, run the Transformer in a loop, take the last word from the output sequence, append it to the Decoder input and feed it to the Decoder for the next iteration. Finally, when the end-of-sentence token is predicted, the Loss' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  31  :  page_content='the Loss function would compare the generated output sequence to the target sequence in order to train the network.Not only would this looping cause training to take much longer, but it also makes it harder to train the model. The model would have to predict the second word based on a potentially' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  32  :  page_content='erroneous first predicted word, and so on.Instead, by feeding the target sequence to the Decoder, we are giving it a hint, so to speak, just like a Teacher would. Even though it predicted an erroneous first word, it can instead use the correct first word to predict the second word so that those' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  33  :  page_content='those errors don’t keep compounding.In addition, the Transformer is able to output all the words in parallel without looping, which greatly speeds up training.What are Transformers used for?Transformers are very versatile and are used for most NLP tasks such as language models and text' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  34  :  page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  35  :  page_content='problems. The basic Encoder Layer is used as a common building block for these architectures, with different application-specific ‘heads’ depending on the problem being solved.Transformer Classification architectureA Sentiment Analysis application, for instance, would take a text document as input.' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  36  :  page_content='as input. A Classification head takes the Transformer’s output and generates predictions of the class labels such as a positive or negative sentiment.(Image by Author)Transformer Language Model architectureA Language Model architecture would take the initial part of an input sequence such as a text' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  37  :  page_content='as a text sentence as input, and generate new text by predicting sentences that would follow. A Language Model head takes the Transformer’s output and generates a probability for every word in the vocabulary. The highest probability word becomes the predicted output for the next word in the' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  38  :  page_content='in the sentence.(Image by Author)How are they better than RNNs?RNNs and their cousins, LSTMs and GRUs, were the de facto architecture for all NLP applications until Transformers came along and dethroned them.RNN-based sequence-to-sequence models performed well, and when the Attention mechanism was' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  39  :  page_content='was first introduced, it was used to enhance their performance.However, they had two limitations:It was challenging to deal with long-range dependencies between words that were spread far apart in a long sentence.They process the input sequence sequentially one word at a time, which means that it' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  40  :  page_content='that it cannot do the computation for time-step t until it has completed the computation for time-step t — 1. This slows down training and inference.As an aside, with CNNs, all of the outputs can be computed in parallel, which makes convolutions much faster. However, they also have limitations in' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  41  :  page_content='in dealing with long-range dependencies:In a convolutional layer, only parts of the image (or words if applied to text data) that are close enough to fit within the kernel size can interact with each other. For items that are further apart, you need a much deeper network with many layers.The' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  42  :  page_content='Transformer architecture addresses both of these limitations. It got rid of RNNs altogether and relied exclusively on the benefits of Attention.They process all the words in the sequence in parallel, thus greatly speeding up computation.(Image by Author)The distance between words in the input' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  43  :  page_content='the input sequence does not matter. It is equally good at computing dependencies between adjacent words and words that are far apart.Now that we have a high-level idea of what a Transformer is, we can go deeper into its internal functionality in the next article to understand the details of how it' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  44  :  page_content='of how it works.And finally, if you liked this article, you might also enjoy my other series on Audio Deep Learning, Geolocation Machine Learning, and Image Caption architectures.Audio Deep Learning Made Simple (Part 1): State-of-the-Art TechniquesA Gentle Guide to the world of disruptive deep' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  45  :  page_content='deep learning audio applications and architectures. And why we all need to…towardsdatascience.comLeveraging Geolocation Data for Machine Learning: Essential TechniquesA Gentle Guide to Feature Engineering and Visualization with Geospatial data, in Plain Englishtowardsdatascience.comImage Captions' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  46  :  page_content='Captions with Deep Learning: State-of-the-Art ArchitecturesA Gentle Guide to Image Feature Encoders, Sequence Decoders, Attention, and Multi-modal Architectures, in Plain Englishtowardsdatascience.comLet’s keep learning!Deep LearningMachine LearningNLPData ScienceArtificial' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n",
            "Chunk  47  :  page_content='Intelligence----23FollowWritten by Ketan Doshi5.9K Followers·Writer for Towards Data ScienceMachine Learning and Big DataFollowHelpStatusAboutCareersPressBlogPrivacyTermsText to speechTeams' metadata={'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science', 'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_vectorstore = Chroma(\n",
        "                          collection_name=\"multi_prompt_rag\",\n",
        "                          embedding_function=emb,\n",
        "                          persist_directory=\"./multi_vectorstore\")\n",
        "multi_vectorstore.add_documents(all_splits)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WhUKBZxKmJRN",
        "outputId": "49f565e7-3aa3-42c9-e7a1-01c22f47d61b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-13-d9b64d3e4148>:1: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the langchain-chroma package and should be used instead. To use it run `pip install -U langchain-chroma` and import as `from langchain_chroma import Chroma`.\n",
            "  multi_vectorstore = Chroma(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['03328a76-3620-4a88-92b4-edd321357286',\n",
              " 'ee3cc3c5-192f-4c5e-8769-e7e68888b40a',\n",
              " '2eedea41-cd29-47b3-ae25-c893fc82e8c7',\n",
              " '34fbe826-33be-4a97-bf54-af649a28e7be',\n",
              " '1bebb314-c0e9-4c2e-b8f6-8077329c4f6d',\n",
              " '6a05d67b-68b3-4a6f-83c5-c1812b0ad300',\n",
              " 'e76ad752-549d-4bd3-9feb-8a6634e6031a',\n",
              " 'c9273be5-8163-41a8-af49-f6d4dc866356',\n",
              " 'feb7beec-10c7-4fbc-9502-3ef7154c339d',\n",
              " 'fedd899f-b1bc-499e-8246-174b44110aff',\n",
              " '1e2d5119-b16c-4261-a038-06c60a6e45ed',\n",
              " 'a798f30f-1f12-4b77-a38d-aa80f5dfb12b',\n",
              " '5ca3c61e-c9aa-4ba1-a009-f8d10a165d22',\n",
              " '612f2d0f-056d-4cc4-8c32-5e6fe8009f8d',\n",
              " '1e423d9d-c99e-4905-ad33-d817dae6db9b',\n",
              " '2794c800-fa39-4d09-8f3f-661058a4a35c',\n",
              " 'a7870828-47e1-45aa-bbd5-1611c8b87c84',\n",
              " 'c21d23af-19d4-4b5f-af1d-c8a9ccaa068f',\n",
              " '908303d1-8015-4180-a3e8-bc971340a13c',\n",
              " '1fbba878-05e6-4c04-9e11-d275c07e9c3b',\n",
              " 'cc6db141-5069-4a57-bbad-71de34009cb8',\n",
              " 'd0f129fa-9089-4c2b-9664-f4c9bd7381e7',\n",
              " '2f8f93d0-0c97-4812-b335-6256928a8e39',\n",
              " '2e9b7044-6b28-4cbc-8e49-68461e903e3a',\n",
              " '67176400-bd99-453d-80dd-cb3a379ecc83',\n",
              " '5bf076c8-7967-4b72-87b6-339975165cbd',\n",
              " '2f9b004c-064f-4a00-bfdb-15be8ca9fd8a',\n",
              " '3bd0a11f-504e-419e-8610-9922e1123d17',\n",
              " '05c8ff12-250b-42ec-80fa-d8e10e8eb7a9',\n",
              " '097afc7e-3580-47f6-85eb-8de33c442cf0',\n",
              " '437830b7-2253-4b54-9a42-80dc8d36f018',\n",
              " '0505ae68-05c0-4635-acc6-0435894445f3',\n",
              " '74affce9-ed4c-4be6-bea4-8fbea0b79e60',\n",
              " 'bef5c17f-e463-4a35-a76c-0d911570f47b',\n",
              " 'bca9791e-d41f-42c1-a174-8e2dc9108f29',\n",
              " 'd1e1872d-ab4a-4b64-baf3-e93eeaf0ee0b',\n",
              " '7ef194c1-1556-4f14-8f77-bce55115a85b',\n",
              " 'f6af325d-73e0-4fef-93e3-2316d0ec0848',\n",
              " '38c7cb5b-e44e-4580-8e12-31b0d4a71690',\n",
              " '2394a7be-1550-4b24-8f29-8de0af61d5bc',\n",
              " 'c9105376-32e8-4aab-b00d-40f9fd465c3d',\n",
              " '1bbaaf9b-4e59-4813-853e-bc577972637b',\n",
              " '1b690b67-6c94-4d6e-8c88-792addfb5c96',\n",
              " '94d2b55b-620f-4e14-af93-d10cf1e7acb9',\n",
              " 'c4ea044b-1cf3-45f7-8cc6-98586eeb68c2',\n",
              " '68af05d1-e968-4c8a-ae75-d479e5f43ea5',\n",
              " '2fa5c9c5-0386-4455-becb-cd5fe474178c',\n",
              " '847e21c2-5ea9-4a18-b76e-0cabee4e8651']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mrag_retriever = multi_vectorstore.as_retriever()\n",
        "mrag_retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUw2yjX_mYct",
        "outputId": "a21af33f-e6f1-45f4-f997-3fc98682b5f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x798ddb68f280>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mrag_retriever_chain = mpromt_chain | mrag_retriever.map()\n",
        "mrag_retriever_chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZphFPdcnY3s",
        "outputId": "a24c1f46-65a8-4b4b-9418-0e6f2a2a831c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate three\\ndifferent versions of the given user question to retrieve relevant documents from a vector\\ndatabase. By generating multiple perspectives on the user question, your goal is to help\\nthe user overcome some of the limitations of the distance-based similarity search.\\nProvide these alternative questions separated by newlines. Original question: {question}'))])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x798de8061ba0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x798de8063ca0>, root_client=<openai.OpenAI object at 0x798de8244c10>, root_async_client=<openai.AsyncOpenAI object at 0x798de8061c00>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "| StrOutputParser()\n",
              "| RunnableLambda(convert_queries_to_list)\n",
              "| RunnableEach(bound=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x798ddb68f280>))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = mrag_retriever_chain.invoke({\"question\": \"Explain Transformer Classification architecture\"})\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5xw4sB32nmYQ",
        "outputId": "821aab73-1f83-4042-bd6b-1a3ebe24ffd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.')],\n",
              " [Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.')],\n",
              " [Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='as input. A Classification head takes the Transformer’s output and generates predictions of the class labels such as a positive or negative sentiment.(Image by Author)Transformer Language Model architectureA Language Model architecture would take the initial part of an input sequence such as a text'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='as input. A Classification head takes the Transformer’s output and generates predictions of the class labels such as a positive or negative sentiment.(Image by Author)Transformer Language Model architectureA Language Model architecture would take the initial part of an input sequence such as a text'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='as input. A Classification head takes the Transformer’s output and generates predictions of the class labels such as a positive or negative sentiment.(Image by Author)Transformer Language Model architectureA Language Model architecture would take the initial part of an input sequence such as a text'),\n",
              "  Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='as input. A Classification head takes the Transformer’s output and generates predictions of the class labels such as a positive or negative sentiment.(Image by Author)Transformer Language Model architectureA Language Model architecture would take the initial part of an input sequence such as a text')]]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_docs(docs):\n",
        "    merged_docs = []\n",
        "    for doc_list in docs:\n",
        "        merged_docs.extend(doc_list)\n",
        "    return merged_docs\n",
        "\n",
        "def remove_duplicates(docs):\n",
        "    seen = set()\n",
        "    unique_docs = []\n",
        "    for doc in docs:\n",
        "        if doc.page_content not in seen:\n",
        "            seen.add(doc.page_content)\n",
        "            unique_docs.append(doc)\n",
        "    return unique_docs"
      ],
      "metadata": {
        "id": "_cLsHm39nr1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mprompt_final =  mrag_retriever_chain | merge_docs | remove_duplicates\n",
        "mprompt_final"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKADuRzhoZbB",
        "outputId": "0d6b19b3-b24d-4369-e7ba-0e555650e7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template='You are an AI language model assistant. Your task is to generate three\\ndifferent versions of the given user question to retrieve relevant documents from a vector\\ndatabase. By generating multiple perspectives on the user question, your goal is to help\\nthe user overcome some of the limitations of the distance-based similarity search.\\nProvide these alternative questions separated by newlines. Original question: {question}'))])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x798de8061ba0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x798de8063ca0>, root_client=<openai.OpenAI object at 0x798de8244c10>, root_async_client=<openai.AsyncOpenAI object at 0x798de8061c00>, model_name='gpt-4o-mini', openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "| StrOutputParser()\n",
              "| RunnableLambda(convert_queries_to_list)\n",
              "| RunnableEach(bound=VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x798ddb68f280>))\n",
              "| RunnableLambda(merge_docs)\n",
              "| RunnableLambda(remove_duplicates)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = mprompt_final.invoke({\"question\": \"Explain Transformer Classification architecture\"})\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0tkVclAon5z",
        "outputId": "16807015-0ec9-4b8f-e263-ac94cd7ce338"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'description': 'A Gentle Guide to Transformers, how they are used for NLP, and why they are better than RNNs, in Plain English. How Attention helps improve performance.', 'language': 'en', 'source': 'https://towardsdatascience.com/transformers-explained-visually-part-1-overview-of-functionality-95a6dd460452', 'title': 'Transformers Explained Visually (Part 1): Overview of Functionality | by Ketan Doshi | Towards Data Science'}, page_content='and text classification. They are frequently used in sequence-to-sequence models for applications such as Machine Translation, Text Summarization, Question-Answering, Named Entity Recognition, and Speech Recognition.There are different flavors of the Transformer architecture for different problems.')]"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mprompt_final.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbXlOCAKtPJm",
        "outputId": "5bdcd079-e15f-4635-88a0-25f14ea41c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      +-------------+        \n",
            "      | PromptInput |        \n",
            "      +-------------+        \n",
            "              *              \n",
            "              *              \n",
            "              *              \n",
            "   +--------------------+    \n",
            "   | ChatPromptTemplate |    \n",
            "   +--------------------+    \n",
            "              *              \n",
            "              *              \n",
            "              *              \n",
            "       +------------+        \n",
            "       | ChatOpenAI |        \n",
            "       +------------+        \n",
            "              *              \n",
            "              *              \n",
            "              *              \n",
            "    +-----------------+      \n",
            "    | StrOutputParser |      \n",
            "    +-----------------+      \n",
            "              *              \n",
            "              *              \n",
            "              *              \n",
            "+-------------------------+  \n",
            "| convert_queries_to_list |  \n",
            "+-------------------------+  \n",
            "              *              \n",
            "              *              \n",
            "              *              \n",
            "  +----------------------+   \n",
            "  | VectorStoreRetriever |   \n",
            "  +----------------------+   \n",
            "              *              \n",
            "              *              \n",
            "              *              \n",
            "       +------------+        \n",
            "       | merge_docs |        \n",
            "       +------------+        \n",
            "              *              \n",
            "              *              \n",
            "              *              \n",
            "    +-------------------+    \n",
            "    | remove_duplicates |    \n",
            "    +-------------------+    \n",
            "              *              \n",
            "              *              \n",
            "              *              \n",
            "+--------------------------+ \n",
            "| remove_duplicates_output | \n",
            "+--------------------------+ \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"Answer the following question based on this context:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "multi_prompt_rag_chain = (\n",
        "    {\"context\": mprompt_final, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | parser\n",
        ")"
      ],
      "metadata": {
        "id": "DWhLxwsVpLVS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "multi_prompt_rag_chain.invoke({\"question\": \"Explain Transformer Classification architecture\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "1HZpn-0ltmry",
        "outputId": "dddc20f8-ed80-4579-b06d-debb985b1fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Transformer architecture is a powerful model used primarily in Natural Language Processing (NLP) tasks, including text classification. It operates based on a mechanism called \"self-attention,\" which allows the model to weigh the significance of different words in a sentence, regardless of their position. This is in contrast to traditional models like Recurrent Neural Networks (RNNs), which process data sequentially and can struggle with long-range dependencies.\\n\\nIn the context of text classification, the Transformer architecture typically involves the following components:\\n\\n1. **Input Representation**: Text data is transformed into embeddings, which represent words or tokens in a continuous vector space. This often includes positional encodings to maintain the order of words.\\n\\n2. **Self-Attention Mechanism**: The self-attention layer allows the model to focus on different parts of the input sequence when making predictions. It calculates attention scores to determine how much focus to give to other words in the sequence relative to the current word.\\n\\n3. **Feedforward Neural Networks**: After the self-attention layer, the output is passed through feedforward neural networks, which apply further transformations to the data.\\n\\n4. **Layer Normalization and Residual Connections**: These techniques are used to stabilize and enhance the learning process, allowing for deeper networks without degradation of performance.\\n\\n5. **Output Layer**: For classification tasks, the final layer typically uses a softmax function to produce probabilities for each class.\\n\\nThe architecture can be adapted for different problems by modifying the number of layers, the size of embeddings, and other hyperparameters. Overall, the Transformer’s ability to process information in parallel and handle dependencies effectively makes it superior for tasks such as text classification compared to older models like RNNs.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "multi_prompt_rag_chain.get_graph().print_ascii()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lvUZWwWUtn8M",
        "outputId": "40f05ae8-dc36-47d1-cf5c-3752f83bc6d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               +---------------------------------+           \n",
            "               | Parallel<context,question>Input |           \n",
            "               +---------------------------------+           \n",
            "                      ****               ****                \n",
            "                   ***                       ***             \n",
            "                 **                             ***          \n",
            "  +--------------------+                           **        \n",
            "  | ChatPromptTemplate |                            *        \n",
            "  +--------------------+                            *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "      +------------+                                *        \n",
            "      | ChatOpenAI |                                *        \n",
            "      +------------+                                *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "    +-----------------+                             *        \n",
            "    | StrOutputParser |                             *        \n",
            "    +-----------------+                             *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "+-------------------------+                         *        \n",
            "| convert_queries_to_list |                         *        \n",
            "+-------------------------+                         *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "  +----------------------+                          *        \n",
            "  | VectorStoreRetriever |                          *        \n",
            "  +----------------------+                          *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "      +------------+                                *        \n",
            "      | merge_docs |                                *        \n",
            "      +------------+                                *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "              *                                     *        \n",
            "   +-------------------+                    +-------------+  \n",
            "   | remove_duplicates |                    | Passthrough |  \n",
            "   +-------------------+                    +-------------+  \n",
            "                      ****               ****                \n",
            "                          ***         ***                    \n",
            "                             **     **                       \n",
            "               +----------------------------------+          \n",
            "               | Parallel<context,question>Output |          \n",
            "               +----------------------------------+          \n",
            "                                 *                           \n",
            "                                 *                           \n",
            "                                 *                           \n",
            "                      +--------------------+                 \n",
            "                      | ChatPromptTemplate |                 \n",
            "                      +--------------------+                 \n",
            "                                 *                           \n",
            "                                 *                           \n",
            "                                 *                           \n",
            "                          +------------+                     \n",
            "                          | ChatOpenAI |                     \n",
            "                          +------------+                     \n",
            "                                 *                           \n",
            "                                 *                           \n",
            "                                 *                           \n",
            "                       +-----------------+                   \n",
            "                       | StrOutputParser |                   \n",
            "                       +-----------------+                   \n",
            "                                 *                           \n",
            "                                 *                           \n",
            "                                 *                           \n",
            "                    +-----------------------+                \n",
            "                    | StrOutputParserOutput |                \n",
            "                    +-----------------------+                \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7Bj9kbKtuIeL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}